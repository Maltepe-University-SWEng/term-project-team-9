[![Review Assignment Due Date](https://classroom.github.com/assets/deadline-readme-button-22041afd0340ce965d47ae6ef1cefeee28c7c493a6346c4f15d667ab976d596c.svg)](https://classroom.github.com/a/oZBp5p5Q)

# ğŸ§  Large Language Model ve FÄ±kra Ãœretimi 

Bu proje, Maltepe Ãœniversitesi YazÄ±lÄ±m MÃ¼hendisliÄŸi Ã¶ÄŸrencileri tarafÄ±ndan Software Project Management dersi kapsamÄ±nda geliÅŸtirilmiÅŸtir.  
AmacÄ±mÄ±z, doÄŸal dil iÅŸleme (NLP) alanÄ±ndaki bilgi birikimimizi kullanarak TÃ¼rk kÃ¼ltÃ¼rÃ¼ne Ã¶zgÃ¼ mizahi metinler (fÄ±kra) Ã¼retebilen bir yapay zeka uygulamasÄ± geliÅŸtirmekti.

Projenin merkezinde, iki farklÄ± yaklaÅŸÄ±m yer almaktadÄ±r:

- ğŸ§ª **SÄ±fÄ±rdan EÄŸitilen KÃ¼Ã§Ã¼k Ã–lÃ§ekli LLM (Transformer tabanlÄ±)**  
- ğŸ”§ **Mevcut GPT-2 modelinin TÃ¼rkÃ§e fÄ±kra veri setiyle fine-tune edilmesi**

Her iki model de fÄ±kra Ã¼retme amacÄ±yla test edilmiÅŸtir. Bu sayede hem kendi eÄŸittiÄŸimiz kÃ¼Ã§Ã¼k bir modelin sÄ±nÄ±rlarÄ±nÄ± gÃ¶zlemleme hem de hazÄ±r bÃ¼yÃ¼k bir dil modelini adapte ederek performans farklarÄ±nÄ± analiz etme fÄ±rsatÄ±mÄ±z oldu.

---

## ğŸš€ Uygulama Ã–zeti

Proje, kullanÄ±cÄ± dostu bir **Streamlit** arayÃ¼zÃ¼ Ã¼zerinden Ã§alÄ±ÅŸÄ±r. KullanÄ±cÄ± "FÄ±kra Ãœret" butonuna bastÄ±ÄŸÄ±nda, arka plandaki modelle oluÅŸturulmuÅŸ anlamlÄ± ve mizahi bir fÄ±kra sunulur.  
Model TÃ¼rkÃ§e dilinde eÄŸitildiÄŸi iÃ§in metinler tutarlÄ± ve kÃ¼ltÃ¼rel olarak yerel deÄŸerlere uygundur.

---

## ğŸ”§ KullanÄ±lan Teknolojiler

- Python 3.10+
- PyTorch
- Hugging Face Transformers
- Streamlit
- Google Colab (model eÄŸitimi iÃ§in)
- Kaggle (model eÄŸitimi iÃ§in)
- GitHub (sÃ¼rÃ¼m kontrolÃ¼ ve iÅŸ birliÄŸi)

---



